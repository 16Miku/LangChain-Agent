# ============================================================
# RAG Search Tool - è°ƒç”¨ rag-service æ··åˆæ£€ç´¢ API
# ============================================================

import os
import httpx
from typing import Optional, List
from langchain_core.tools import tool
from pydantic import BaseModel, Field


def get_rag_service_url() -> str:
    """è·å– RAG Service URLï¼Œä¼˜å…ˆä» chat-service é…ç½®è·å–"""
    # é¦–å…ˆå°è¯•ç¯å¢ƒå˜é‡
    url = os.getenv("RAG_SERVICE_URL")
    if url:
        return url

    # å°è¯•ä» chat-service é…ç½®è·å–
    try:
        from app.config import settings
        return settings.RAG_SERVICE_URL
    except ImportError:
        pass

    # é»˜è®¤å€¼
    return "http://localhost:8004"


def get_internal_service_key() -> str:
    """è·å–å†…éƒ¨æœåŠ¡å¯†é’¥"""
    # é¦–å…ˆå°è¯•ç¯å¢ƒå˜é‡
    key = os.getenv("INTERNAL_SERVICE_KEY")
    if key:
        return key

    # å°è¯•ä» chat-service é…ç½®è·å–
    try:
        from app.config import settings
        return settings.INTERNAL_SERVICE_KEY
    except ImportError:
        pass

    # é»˜è®¤å€¼
    return "internal-service-key-change-in-production"


def get_auth_headers() -> dict:
    """è·å–è®¤è¯è¯·æ±‚å¤´"""
    return {
        "Authorization": f"Bearer {get_internal_service_key()}"
    }


def get_http_client(timeout: float = 15.0) -> httpx.AsyncClient:
    """
    è·å– HTTP å®¢æˆ·ç«¯ï¼Œç¦ç”¨ä»£ç†ä»¥è®¿é—®æœ¬åœ°æœåŠ¡

    Args:
        timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´

    Returns:
        é…ç½®å¥½çš„ AsyncClient
    """
    # ç¦ç”¨ä»£ç†ï¼Œé¿å…æœ¬åœ°æœåŠ¡è¯·æ±‚èµ°ä»£ç†å¯¼è‡´ 502 é”™è¯¯
    return httpx.AsyncClient(
        timeout=timeout,
        proxy=None,  # æ˜¾å¼ç¦ç”¨ä»£ç†
        trust_env=False  # ä¸è¯»å–ç¯å¢ƒå˜é‡ä¸­çš„ä»£ç†è®¾ç½®
    )


class Citation(BaseModel):
    """å¼•ç”¨ä¿¡æ¯"""
    chunk_id: str
    document_id: str
    document_name: str
    page_number: Optional[int] = None
    section: Optional[str] = None
    content: str
    content_preview: Optional[str] = None
    score: float


class SearchResult(BaseModel):
    """æœç´¢ç»“æœ"""
    chunk_id: str
    document_id: str
    document_name: str
    content: str
    page_number: Optional[int] = None
    score: float
    vector_score: Optional[float] = None
    bm25_score: Optional[float] = None
    rerank_score: Optional[float] = None


@tool
async def rag_search(
    query: str,
    top_k: int = 10,
    rerank: bool = True,
) -> str:
    """
    ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³æ–‡æ¡£å†…å®¹ã€‚ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆå‘é‡+BM25+é‡æ’åºï¼‰è·å–æœ€ç›¸å…³çš„ç»“æœã€‚

    å½“ç”¨æˆ·è¯¢é—®ä¸å·²ä¸Šä¼ æ–‡æ¡£ç›¸å…³çš„é—®é¢˜æ—¶ï¼Œä½¿ç”¨æ­¤å·¥å…·æ£€ç´¢ç›¸å…³å†…å®¹ã€‚

    Args:
        query: ç”¨æˆ·çš„é—®é¢˜æˆ–æœç´¢æŸ¥è¯¢
        top_k: è¿”å›çš„ç»“æœæ•°é‡ï¼Œé»˜è®¤10æ¡
        rerank: æ˜¯å¦ä½¿ç”¨é‡æ’åºæå‡ç»“æœè´¨é‡ï¼Œé»˜è®¤True

    Returns:
        æ£€ç´¢åˆ°çš„ç›¸å…³æ–‡æ¡£å†…å®¹ï¼ŒåŒ…å«å¼•ç”¨æ¥æºä¿¡æ¯
    """
    print(f"\nğŸ” [RAG Search] æ­£åœ¨æ£€ç´¢çŸ¥è¯†åº“: {query}")
    print(f"   å‚æ•°: top_k={top_k}, rerank={rerank}")

    try:
        rag_url = get_rag_service_url()
        headers = get_auth_headers()
        async with get_http_client(timeout=30.0) as client:
            # è°ƒç”¨ rag-service æ··åˆæ£€ç´¢ API
            response = await client.post(
                f"{rag_url}/api/v1/search",
                headers=headers,
                json={
                    "query": query,
                    "top_k": top_k,
                    "alpha": 0.5,  # å‘é‡å’ŒBM25æƒé‡å„50%
                    "rerank": rerank,
                }
            )

            if response.status_code != 200:
                error_detail = response.text
                print(f"âŒ [RAG Search] APIé”™è¯¯: {response.status_code} - {error_detail}")
                return f"æ£€ç´¢å¤±è´¥: {error_detail}"

            data = response.json()

            results = data.get("results", [])
            citations = data.get("citations", [])
            search_time = data.get("search_time_ms", 0)
            total = data.get("total", 0)

            print(f"âœ… [RAG Search] æ‰¾åˆ° {total} æ¡ç»“æœ (è€—æ—¶ {search_time}ms)")

            if not results:
                return "æœªåœ¨çŸ¥è¯†åº“ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚è¯·ç¡®è®¤å·²ä¸Šä¼ ç›¸å…³æ–‡æ¡£ï¼Œæˆ–å°è¯•ç”¨ä¸åŒçš„å…³é”®è¯æœç´¢ã€‚"

            # æ ¼å¼åŒ–è¾“å‡º
            output_parts = [f"ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢åˆ° {len(results)} æ¡ç›¸å…³å†…å®¹:\n"]

            for i, result in enumerate(results, 1):
                doc_name = result.get("document_name", "æœªçŸ¥æ–‡æ¡£")
                content = result.get("content", "")
                page_num = result.get("page_number")
                score = result.get("score", 0)

                # æ„å»ºå¼•ç”¨æ ‡è¯†
                page_info = f" (ç¬¬{page_num}é¡µ)" if page_num else ""

                output_parts.append(f"---\n**[{i}] {doc_name}{page_info}** (ç›¸å…³åº¦: {score:.2f})\n")
                output_parts.append(f"{content}\n")

            # æ·»åŠ å¼•ç”¨è¿½æº¯ä¿¡æ¯
            if citations:
                output_parts.append("\n---\n**å¼•ç”¨æ¥æº:**\n")
                for cit in citations[:5]:  # æœ€å¤šæ˜¾ç¤º5æ¡å¼•ç”¨
                    cit_doc = cit.get("document_name", "æœªçŸ¥")
                    cit_page = cit.get("page_number")
                    cit_section = cit.get("section", "")
                    page_str = f"ç¬¬{cit_page}é¡µ" if cit_page else ""
                    section_str = f" - {cit_section}" if cit_section else ""
                    output_parts.append(f"- {cit_doc} {page_str}{section_str}\n")

            return "".join(output_parts)

    except httpx.TimeoutException:
        print("âŒ [RAG Search] è¯·æ±‚è¶…æ—¶")
        return "æ£€ç´¢è¯·æ±‚è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    except httpx.ConnectError:
        print("âŒ [RAG Search] æ— æ³•è¿æ¥åˆ° RAG æœåŠ¡")
        return "æ— æ³•è¿æ¥åˆ°çŸ¥è¯†åº“æœåŠ¡ï¼Œè¯·ç¡®è®¤æœåŠ¡å·²å¯åŠ¨ã€‚"
    except Exception as e:
        print(f"âŒ [RAG Search] é”™è¯¯: {e}")
        return f"æ£€ç´¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


@tool
async def list_knowledge_documents() -> str:
    """
    åˆ—å‡ºçŸ¥è¯†åº“ä¸­å·²ä¸Šä¼ çš„æ‰€æœ‰æ–‡æ¡£ã€‚

    å½“ç”¨æˆ·è¯¢é—®"çŸ¥è¯†åº“æœ‰å“ªäº›æ–‡æ¡£"ã€"æˆ‘ä¸Šä¼ äº†ä»€ä¹ˆæ–‡ä»¶"ç­‰é—®é¢˜æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚

    Returns:
        çŸ¥è¯†åº“ä¸­çš„æ–‡æ¡£åˆ—è¡¨ï¼ŒåŒ…å«æ–‡ä»¶åã€å¤§å°ã€çŠ¶æ€ç­‰ä¿¡æ¯
    """
    rag_url = get_rag_service_url()
    print(f"\nğŸ“š [RAG] æ­£åœ¨è·å–çŸ¥è¯†åº“æ–‡æ¡£åˆ—è¡¨... (URL: {rag_url})")

    try:
        headers = get_auth_headers()
        print(f"   Headers: Authorization=Bearer ***")

        async with get_http_client(timeout=15.0) as client:
            full_url = f"{rag_url}/api/v1/documents"
            print(f"   Requesting: GET {full_url}")

            response = await client.get(
                full_url,
                headers=headers,
                params={"skip": 0, "limit": 50}
            )

            print(f"   Response status: {response.status_code}")

            if response.status_code != 200:
                error_text = response.text[:500] if response.text else "No error details"
                print(f"   Error: {error_text}")
                return f"è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥ (HTTP {response.status_code}): {error_text}"

            data = response.json()
            documents = data.get("documents", [])
            total = data.get("total", 0)

            print(f"âœ… [RAG] è·å–åˆ° {total} ä¸ªæ–‡æ¡£")

            if not documents:
                return "çŸ¥è¯†åº“ä¸­æš‚æ— æ–‡æ¡£ã€‚æ‚¨å¯ä»¥åœ¨è®¾ç½®é¡µé¢çš„ã€ŒKnowledgeã€æ ‡ç­¾é¡µä¸Šä¼ æ–‡æ¡£ã€‚"

            # æ ¼å¼åŒ–è¾“å‡º
            output_parts = [f"çŸ¥è¯†åº“ä¸­å…±æœ‰ {total} ä¸ªæ–‡æ¡£:\n\n"]

            for doc in documents:
                filename = doc.get("filename", "æœªçŸ¥")
                file_size = doc.get("file_size", 0)
                chunk_count = doc.get("chunk_count", 0)
                status = doc.get("status", "unknown")

                # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                if file_size < 1024:
                    size_str = f"{file_size} B"
                elif file_size < 1024 * 1024:
                    size_str = f"{file_size / 1024:.1f} KB"
                else:
                    size_str = f"{file_size / (1024 * 1024):.1f} MB"

                # çŠ¶æ€æ˜ å°„
                status_map = {
                    "ready": "âœ… å°±ç»ª",
                    "processing": "â³ å¤„ç†ä¸­",
                    "error": "âŒ é”™è¯¯",
                    "pending": "â¸ï¸ ç­‰å¾…ä¸­"
                }
                status_str = status_map.get(status, status)

                output_parts.append(f"- **{filename}** ({size_str}, {chunk_count}ä¸ªåˆ†å—) {status_str}\n")

            return "".join(output_parts)

    except httpx.TimeoutException as e:
        print(f"âŒ [RAG] è¶…æ—¶: {e}")
        return "è·å–æ–‡æ¡£åˆ—è¡¨è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚"
    except httpx.ConnectError as e:
        print(f"âŒ [RAG] è¿æ¥å¤±è´¥: {e}")
        return f"æ— æ³•è¿æ¥åˆ°çŸ¥è¯†åº“æœåŠ¡ ({rag_url})ï¼Œè¯·ç¡®è®¤ rag-service å·²å¯åŠ¨ã€‚"
    except Exception as e:
        print(f"âŒ [RAG] é”™è¯¯: {type(e).__name__}: {e}")
        return f"è·å–æ–‡æ¡£åˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
